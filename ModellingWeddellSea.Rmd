---
title: "Modelling Weddell Sea Food Web"
author: "L.A.S."
output: html_document
editor_options: 
  chunk_output_type: console
---

## Setup

```{r setup, eval=TRUE,echo=F,message=T,warning=T}

if(file.exists(".RData")) load(".RData")

require(igraph)
require(multiweb)
require(tidyverse)
source("R/network_fun.r")


```

## Read Weddell Sea Data from GATEWAY 

* Initially we read this an then we saved it with less fields to add information not present in the database about dimensionality of interactions 2D or 3D

```{r readWeddell, eval=FALSE,echo=F,message=T,warning=T}


#
# Read and check data available on GATEWAy about Weddell Sea
#
# Read the original database
#
ga <- readr::read_csv("Data/283_2_FoodWebDataBase_2018_12_10.csv",col_types = "icccccccccccccddddddccccccccddddddcddccddciicc")
names(ga)
wedd_df <-  ga %>%filter(grepl('Weddell',foodweb.name))  #saveRDS(wedd_df, "Data/wedd_df.rds")

# Check all species are in res.taxonomy 
names(wedd_df)

# Rename and Select fields 

wedd_df <- wedd_df %>% rename(con_mass_mean=con.mass.mean.g.,res_mass_mean=res.mass.mean.g.,con_taxonomy=con.taxonomy,res_taxonomy=res.taxonomy,interaction_dim=interaction.dimensionality) %>% select(con_taxonomy,res_taxonomy, con_mass_mean,res_mass_mean,interaction_dim)

write_tsv(wedd_df %>% arrange(interaction_dim), "Data/Wedd_mass.dat")
      

#
# Update by hand the missing interaction_dim to a new file called ---> "Data/Wedd_mass_complete.dat"
#


save.image()
```


## Add body masses in g to a data.frame

```{r makeBodyMass, eval=FALSE,echo=F,message=T,warning=T}

# Parameters for alometric equations @Emmerson2004 y ... 
# @Yang2019 --> Parametriza Lotka Volterra
# @Donohue2017 --> Parametriza model derived from Yodzis and Innes (1992), updated with more recent allometric coefficients
# @Fahimipour2014 ---> Estima el flujo a partir de la tasa metabólica y las densidad de la poblacion
# @Carrara2015  --> distintos metodos para estimar interacciones basados en LV
#
# @Petchey2008 LV Parametrization an interesting idea is that it adds Type 2 functional response to check structural robustness 
#
# @Brose2006 Parametrization of consumer–resource model (Yodzis & Innes 1992) updated with new allometric coefficients (Brown et al. 2004)
# and extended to multispecies systems (Williams & Martinez 2004b)
#
# @James2015 Uses @Emerson2004 as a method to get LV interaction strength using body masses 
#
# @Neutel2014 Uses LV parametrized from empirical data 
# @Pawar2012 2D/3D search space + metabolic theory 


# Read the updated database
#
wedd_df <- read_delim("Data/Wedd_mass_complete.dat",delim=" ",col_types="dccddc")


# Check detritus
#
detritus <- wedd_df %>% filter(grepl("tritus",res_taxonomy)) 
detritus <- wedd_df %>% filter(is.na(interaction_dim))


#
# Calculate interaction intensity
#
wedd_df <- wedd_df %>% mutate(res_mass_mean = res_mass_mean*1000,con_mass_mean = con_mass_mean*1000)
wedd_int <- interaction_intensity(wedd_df,res_mass_mean,con_mass_mean,interaction_dim )
  
ggplot(wedd_int, aes(qRC)) +  geom_histogram(bins=50,color="darkblue",fill="white") + theme_bw() + scale_y_log10() 

#
# Convert to an igraph with weights
#

g <- graph_from_data_frame(wedd_int %>% select(res_taxonomy,con_taxonomy,qRC) %>% rename(weight=qRC) ,directed=TRUE)   # the 3d field generate an attribute
E(g)$weight

calc_weighted_topological_indices(g)
calc_topological_indices(g)

rm(detritus,wedd,wedd_df1)
save.image()

``` 


## Calc unweighted topological indices

```{r calc_unweighted_metrics, eval=TRUE,echo=F,message=T,warning=T}

websTbl <- tibble()
curveBallNets <- tibble()

tp <- calcTopologicalIndices(g)
#tp <- bind_cols(tp, calcIncoherence(g1)) 
tp <- bind_cols(tp, calc_QSS(g,10000,48, istrength=FALSE)) 

websTbl <- bind_rows(websTbl, tp)

lred <- curveBall(g,1000)
tp <- calcTopologicalIndices(lred,ncores=48) 

tp0 <- calcModularitySWnessZScore(g,lred,ncores=48)
tp1 <- tp0$da %>% dplyr::select(Modularity:isSWness)
websTbl <- bind_cols(websTbl,tp1)

curveBallNets <- tp0$sims 
rm(tp,tp0,lred,tp1)
save.image()

```


## Calc unweighted topological indices

```{r calc_weighted_metrics, eval=TRUE,echo=F,message=T,warning=T}

weightedNets <- tibble()

weightedTbl <- tibble()
tp <- calc_weighted_topological_indices(g)
#tp <- bind_cols(tp, calcIncoherence(g1)) 
tp <- bind_cols(tp, calc_QSS(g,10000,48, istrength=TRUE)) 


# Modularity should be repeatedly calculated because is a stochastic algorithm
#
plan(multisession)
wm <- future_lapply(seq_len(100),function(X){
  wm <- calc_modularity(g,weights = NULL) 
  })
modularityTbl <- bind_rows(wm %>% mutate(type="weighted"))

tp <- bind_cols(tp, summarise(modularityTbl, Modularity=mean(Modularity)))

weightedTbl <- bind_rows(weightedTbl, tp)                 ## Modularity -49643343 what happens if all the weights have the average weigth valus?????????


lred <- curveBall(g,1000,istrength=TRUE)
tp <- calc_weighted_topological_indices(lred,ncores=48)
tp <- bind_cols(tp, calc_modularity(lred,ncores=48,weights = NULL)) 


# tp0 <- calcModularitySWnessZScore(g,lred,ncores=48)  -----> Against which model do we calculate SWness in the weighed case???????????
# tp1 <- tp0$da %>% dplyr::select(Modularity:isSWness)
# websTbl <- bind_cols(websTbl,tp1)

weightedNets <- tp 
rm(tp,tp0,lred,tp1)
save.image()

```